{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaaf719a-5192-4c8b-b019-4455e19ccd5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Jupyter Notebooks\n",
    "\n",
    "* Interactive computational environment for working with **Ju**lia, **P**ython, and **R** and more (40+ languages)\n",
    "* Composed of input and output cells that can contain code or text (via Markdown) and produce a range of outputs\n",
    "* Enables [literate programming](https://en.wikipedia.org/wiki/Literate_programming) paradigm of text and documentation interleaved with code\n",
    "\n",
    "**_Pro tip: Use more modern JupyterLab over classic Jupyter Notebook_**\n",
    "\n",
    "\n",
    "**_Bonus pro tip: Get comfortable with Jupyter's keybindings_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f835bfc4-3c54-41de-b194-50e04dc61236",
   "metadata": {},
   "source": [
    "There are also a range of useful macros that are extensions beyond Python features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ce625-38d9-4b62-ac5e-1bd29983dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these macros make Jupyter re-run imported libraries when it detects their \n",
    "# contents on disk have changed\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dee720-449e-43e4-9b9c-1118e75e3f12",
   "metadata": {},
   "source": [
    "## Data: Weekly Payroll Jobs and Wages in Australia\n",
    "\n",
    "Data provided by the Australian Bureau of Statistics pertaining to weekly numbers of jobs with payroll data. This is based on the Australian Tax Office's single touch payroll data, which is how most businesses report salaries and wages, pay as you go (PAYG) withholding, and superannuation.\n",
    "\n",
    "[Weekly Jobs and Wages Index for Week ending 21/03/2021.](https://www.abs.gov.au/statistics/labour/earnings-and-work-hours/weekly-payroll-jobs-and-wages-australia/week-ending-27-march-2021#data-download)\n",
    "\n",
    "\n",
    "[Excel file used -- Table 5: Sub-state - Payroll jobs indexes](https://www.abs.gov.au/statistics/labour/earnings-and-work-hours/weekly-payroll-jobs-and-wages-australia/week-ending-27-march-2021/6160055001_DO005.xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f86693-f18e-47bb-90b8-6f82d6c4347f",
   "metadata": {},
   "source": [
    "## Pandas Data Wrangling\n",
    "\n",
    "Pandas is a powerful Swiss Army knife for doing data manipulation and analysis in Python.\n",
    "\n",
    "The two primary data structures it makes available are the `DataFrame`, for working with two-dimensional tabular data, and the `Series` for working with one-dimensional arrays.\n",
    "\n",
    "We'll need to install the `openpyxl` in order to read Excel files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af6a3a-3bcc-428b-91b3-988472b7e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can run shell commands by prefixing with `!`\n",
    "! pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6166c-f8f0-4487-8cd4-9611b8b3087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"data/6160055001_DO005.xlsx\", sheet_name=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ebd2b7-6bf5-461d-a28e-f88013c745e4",
   "metadata": {},
   "source": [
    "Note that Jupyter defaults to displaying the output of the previous cell on execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e209cf-4f16-4aa0-84ff-381cee1d163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d866ff9f-3b08-47a4-b634-8b6a2237bf63",
   "metadata": {},
   "source": [
    "Let's use the `dtale` package to better explore the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d706a-ec0c-436a-a48b-ad6f615609e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtale\n",
    "\n",
    "dtale.show(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11ff51-8474-4840-8cb1-1cf757290224",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_raw_df = pd.read_excel(\n",
    "    \"data/6160055001_DO005.xlsx\",\n",
    "    sheet_name=1,  # zero-indexed, so this is the second sheet!\n",
    "    usecols=\"A:BO\",\n",
    "    skiprows=5,\n",
    "    skipfooter=2,\n",
    ")\n",
    "\n",
    "jobs_raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11262e47-1cc8-4850-af70-3b8d58f625d2",
   "metadata": {},
   "source": [
    "This data is in [wide](https://en.wikipedia.org/wiki/Wide_and_narrow_data) format. We need to make it into long (or narrow) form, where each row contains a single record.\n",
    "\n",
    "We also need to split the first two columns into their codes and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe9b68c-9d35-4626-bd10-ab825d0b8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a DataFrame of all columns except the first two\n",
    "date_cols_df = jobs_raw_df.iloc[:, 2:]\n",
    "\n",
    "# split col 1 into codes and names\n",
    "ste_cols_df = (\n",
    "    jobs_raw_df[jobs_raw_df.columns[0]]\n",
    "    .str.split(r\"\\. \", expand=True)\n",
    "    .rename(columns={0: \"STE_CODE16\", 1: \"STE_NAME16\"})\n",
    ")\n",
    "\n",
    "# split col 2 into codes and names\n",
    "sa4_cols_df = (\n",
    "    jobs_raw_df[jobs_raw_df.columns[1]]\n",
    "    .str.split(r\"\\. \", expand=True)\n",
    "    .rename(columns={0: \"SA4_CODE16\", 1: \"SA4_NAME16\"})\n",
    ")\n",
    "\n",
    "# combine the 3 sets of columns into a single DataFrame, and then use the melt method\n",
    "# to convert it into long format\n",
    "jobs_df = pd.concat([ste_cols_df, sa4_cols_df, date_cols_df], axis=1).melt(\n",
    "    id_vars=[\"STE_CODE16\", \"STE_NAME16\", \"SA4_CODE16\", \"SA4_NAME16\"],\n",
    "    var_name=\"Date\",\n",
    "    value_name=\"Index\",\n",
    ")\n",
    "\n",
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5635900-6a11-4b26-bf81-3225f0926d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0110b9-7771-4426-9003-636f9587f3fe",
   "metadata": {},
   "source": [
    "Let's get the mean index for each state across all dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b4c317-6382-46f5-a697-c97379792351",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_jobs = jobs_df.groupby([\"STE_NAME16\", \"Date\"])[\"Index\"].mean()\n",
    "states_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886ad29d-772b-4522-b561-ecab7721bbd4",
   "metadata": {},
   "source": [
    "Now get the mean of the state means for each date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7f071b-12df-4fac-b097-46e0d61e598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_jobs = states_jobs.mean(level=\"Date\")\n",
    "country_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f9c4ee-835a-44a0-9c29-d343805652e4",
   "metadata": {},
   "source": [
    "# Visualising with Pandas & Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44c9c0-b9d7-47c7-8087-8031ceb4a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Series from previous cell to DataFrame for easier plotting\n",
    "\n",
    "country_jobs_df = country_jobs.reset_index()\n",
    "country_jobs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8f664e-5bb7-4a89-a791-3e7aeba203e7",
   "metadata": {},
   "source": [
    "### Use Pandas' API to make Matplotlib plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ec7fe-2f59-44c4-b12e-c9500455b7f9",
   "metadata": {},
   "source": [
    "We're going to start by using Pandas to plot the wage Index over time.\n",
    "\n",
    "Pandas uses Matplotlib under the hood for plotting. Pandas' [plotting backend](https://pandas.pydata.org/pandas-docs/dev/user_guide/visualization.html#plotting-backends) feature allows other libraries to be used.\n",
    "\n",
    "Current plotting backends available:\n",
    "\n",
    "* [Plotly](https://plotly.com/python/pandas-backend/)\n",
    "* [Bokeh](https://github.com/PatrikHlobil/Pandas-Bokeh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2388654-e712-48ad-8f2d-812be39fa6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell Jupyter to render Matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "country_jobs_df.plot(x=\"Date\", y=\"Index\", title=\"Weekly Payroll Jobs and Wages Index\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7743001b-fcbc-4370-ac3f-bbcbb3367895",
   "metadata": {},
   "source": [
    "**_Pro tip: Always title your plots!_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb12ac-adb5-4036-9d3c-b4eddb2d849d",
   "metadata": {},
   "source": [
    "## Improving Aesthetics of Matplotlib plots\n",
    "\n",
    "**Approach 1: use a theme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccef9df-c35d-49da-b995-3d54d19d8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b76db8-ae9f-46a0-b2d0-e9b46b2a5a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "country_jobs_df.plot(x=\"Date\", y=\"Index\", title=\"Weekly Payroll Jobs and Wages Index\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083e7e6-3078-492e-96d6-edb6e97fdaf6",
   "metadata": {},
   "source": [
    "**Approach 2: Increase the DPI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160bc4a-1a9f-4518-9945-b7db0a639517",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=300, figsize=(15, 5))\n",
    "\n",
    "country_jobs_df.plot(\n",
    "    x=\"Date\", y=\"Index\", ax=plt.gca(), title=\"Weekly Payroll Jobs and Wages Index\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81928236-cd19-4604-a95d-370367850cc0",
   "metadata": {},
   "source": [
    "### Use ipympl Widget for interactivity\n",
    "\n",
    "_Note: this requires the ipympl package to be installed_\n",
    "\n",
    "Let's plot the Index of all states. This is simple with Pandas, but requires our data to be in wide format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3cf2d9-9d11-4089-bfdf-a786d6db884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# use the unstack method to get it into wide format\n",
    "\n",
    "states_jobs.unstack(level=0).plot(\n",
    "    figsize=(15, 5), title=\"Weekly Payroll Jobs and Wages Index by State\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a86ebc1-9fc1-4d97-9edb-1776d31e5422",
   "metadata": {},
   "source": [
    "What if our data was in long (tidy) format?\n",
    "\n",
    "This is harder with Pandas. Easier to use a different tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7283214-1688-49f1-bc26-dfb6f726be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_jobs_df = states_jobs.reset_index()\n",
    "states_jobs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63cddd3-c5eb-4b54-8684-ea3051288b52",
   "metadata": {},
   "source": [
    "## Other plotting Options\n",
    "\n",
    "### Seaborn\n",
    "\n",
    "Like Pandas, Seaborn is built on top of Matplotlib. It provides an API that is particularly well-suited for making more scientific/statistically oriented plots.\n",
    "\n",
    "See the [Seaborn gallery](https://seaborn.pydata.org/examples/index.html) for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6699081c-d691-4a0a-b375-7259c71a95fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=states_jobs_df,\n",
    "    x=\"Date\",\n",
    "    y=\"Index\",\n",
    "    hue=\"STE_NAME16\",\n",
    ").set(title=\"Weekly Payroll Jobs and Wages Index by State\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d8c9e-7daa-4cf9-abe2-1820595f8723",
   "metadata": {},
   "source": [
    "### Plotly\n",
    "\n",
    "Plotly is powered by a JavaScript-based visualisation library that gives you interactive plots out of the box.\n",
    "\n",
    "There is a lower-level Python interface for defining plots as [`Figure` objects](https://plotly.com/python/figure-structure), as well as the more concise [Plotly Express](https://plotly.com/python/plotly-express/) that produces `Figure` objects with much less coding required.\n",
    "\n",
    "A gallery of examples can be found [here](https://plotly.com/python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d864b-c4d4-4b62-b714-5c9c431512fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.line(\n",
    "    states_jobs_df,\n",
    "    x=\"Date\",\n",
    "    y=\"Index\",\n",
    "    color=\"STE_NAME16\",\n",
    "    title=\"Weekly Payroll Jobs and Wages Index by State\",\n",
    "    width=1200,\n",
    "    height=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28197f94-f886-4ae1-b1de-d23a12536a43",
   "metadata": {},
   "source": [
    "### Adding Country-level mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a1856-fa90-4b7b-8707-7e9c4c1b3e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_and_country_df = pd.concat(\n",
    "    [states_jobs_df, country_jobs_df.assign(STE_NAME16=\"AUS\")]\n",
    ")\n",
    "state_names = list(states_jobs_df[\"STE_NAME16\"].unique())\n",
    "\n",
    "px.line(\n",
    "    states_and_country_df,\n",
    "    x=\"Date\",\n",
    "    y=\"Index\",\n",
    "    color=\"STE_NAME16\",\n",
    "    title=\"Weekly Payroll Jobs and Wages Index by State\",\n",
    "    color_discrete_map={\"AUS\": \"black\"},\n",
    "    category_orders={\"STE_NAME16\": [\"AUS\"] + state_names},\n",
    "    line_dash=\"STE_NAME16\",\n",
    "    line_dash_sequence=[\"dot\"] + [\"solid\" for _state in state_names],\n",
    "    width=1200,\n",
    "    height=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb6c627-0082-4c75-b8aa-810937637cc8",
   "metadata": {},
   "source": [
    "### Other options to consider\n",
    "* [Altair](https://altair-viz.github.io/) (similar to ggplot, with good interactive API)\n",
    "* [Holoviews](https://holoviews.org/) (has Matplotlib, Bokeh, and Plotly backends)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd48b7f-9601-44ac-ba17-8b89d484e98a",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"/files/img/python_viz_libs.svg\" width=900/>\n",
    "    <h2><i>Which visualisation library to use?</i></h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41ce9ee-5250-4323-9f25-15d643a0712c",
   "metadata": {},
   "source": [
    "# Spatial Visualisation\n",
    "\n",
    "A useful tool for working with spatial data is [Geopandas](https://geopandas.org/).\n",
    "\n",
    "It provides `GeoSeries` and `GeoDataFrame` data structures, like Pandas' `Series` and `DataFrame`, but for working with shaply objects: \n",
    "* Points / Multi-Points\n",
    "* Lines / Multi-Lines\n",
    "* Polygons / Multi-Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e10ba-a9b0-4119-bbcf-8a6f2de883dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file(\"data/sa4_2016_aust_shape/SA4_2016_AUST.shp\")\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7405459e-2cde-4b89-8bb8-4ecfd85170e2",
   "metadata": {},
   "source": [
    "Like Pandas, Geopandas can produce plots using Matplotlib.\n",
    "\n",
    "## PLotting a Choropleth with Geopandas \n",
    "\n",
    "Let's plot a spatial heat map plat (choropleth) of mean index by SA4 region.\n",
    "\n",
    "We'll wrap it up in a function that takes a data as an input parameter, and filters the data down to results for that date and plots the choropleth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb1c17-5a3c-41a2-b46b-d8dc8ff4f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as cx\n",
    "\n",
    "\n",
    "def plot_wage_chloropleth(sa4_gdf, jobs_df, date):\n",
    "    \"\"\"Plot a chloropleth map of jobs Index for a given date\"\"\"\n",
    "    # remove records with empty geometry, and filter data to current month,\n",
    "    # then join with geo data\n",
    "    sa4_gdf = sa4_gdf[~sa4_gdf[\"geometry\"].isnull()]\n",
    "    filtered_df = jobs_df[jobs_df[\"Date\"] == date]\n",
    "    sa4_gdf = sa4_gdf.merge(filtered_df, on=\"SA4_CODE16\", validate=\"one_to_one\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    sa4_gdf.plot(\n",
    "        ax=ax,\n",
    "        edgecolor=\"black\",\n",
    "        column=\"Index\",\n",
    "        vmin=jobs_df[\"Index\"].min(),\n",
    "        vmax=jobs_df[\"Index\"].max(),\n",
    "    ).set(title=\"Australian Jobs and Wages Index\")\n",
    "\n",
    "    # set the basemap tiles with contexily\n",
    "    cx.add_basemap(ax, crs=gdf.crs.to_string(), source=cx.providers.CartoDB.Voyager)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "plot_wage_chloropleth(gdf, jobs_df, \"2020-01-04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5dca33-09cd-405d-bf26-456e8384d78c",
   "metadata": {},
   "source": [
    "**_Pro tip: Move code for producing distinct plots into function_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05847a63-7da9-4b5f-84a6-b9db7e26fbf6",
   "metadata": {},
   "source": [
    "## Plotting a Choropleth with Folium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487acdb1-2982-4fbc-b675-1793853463d4",
   "metadata": {},
   "source": [
    "Folium is a Python wrapper around the Leaflet JavaScript library for producing web-based interactive maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704fc654-ec3b-4b94-91c9-f14a69267f58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "\n",
    "def plot_wage_chloropleth_folium(sa4_gdf, jobs_df, date):\n",
    "    \"\"\"Plot a chloropleth map of jobs Index for a given date\"\"\"\n",
    "    # remove records with empty geometry, and filter data to current month\n",
    "    sa4_gdf = sa4_gdf[~sa4_gdf[\"geometry\"].isnull()]\n",
    "    filtered_df = jobs_df[jobs_df[\"Date\"] == date]\n",
    "\n",
    "    folium_map = folium.Map(location=[-22, 133], zoom_start=5)\n",
    "\n",
    "    choropleth = folium.Choropleth(\n",
    "        geo_data=sa4_gdf,\n",
    "        data=filtered_df,\n",
    "        columns=[\"SA4_NAME16\", \"Index\"],\n",
    "        key_on=\"feature.properties.SA4_NAME16\",\n",
    "        fill_color=\"YlGn\",\n",
    "        fill_opacity=0.7,\n",
    "        line_opacity=0.2,\n",
    "        legend_name=\"Wage Index\",\n",
    "        highlight=True,\n",
    "    )\n",
    "    choropleth.geojson.add_child(\n",
    "        folium.features.GeoJsonTooltip([\"SA4_NAME16\"], labels=False)\n",
    "    )\n",
    "    choropleth.add_to(folium_map)\n",
    "    folium.LayerControl().add_to(folium_map)\n",
    "    return folium_map\n",
    "\n",
    "\n",
    "plot_wage_chloropleth_folium(gdf, jobs_df, \"2020-01-04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58cc0ea-ec4e-499e-a3c8-4471d8b5e70b",
   "metadata": {},
   "source": [
    "Note that in the above solution, the color map is not being mapped to the ranges of the data from the whole year. This seems to be trickier to do with Folium's choropleth than GeoPandas' choropleth.\n",
    "\n",
    "Working hypothesis is that for choropleth's needing any kind of customisation, the best way to approach is to user the lower-level `folium.GeoJson` class and set the `style_function` and `highlight_function` parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60130efb-3098-4c14-ad59-acfabef734b5",
   "metadata": {},
   "source": [
    "## Other options to consider:\n",
    "\n",
    "* [ipyleaflet](https://ipyleaflet.readthedocs.io/), for creating Leaflet plots along with interactive ipywidget controls.\n",
    "* [Geoviews](https://geoviews.org/) (related to the Holoviews project)\n",
    "* [Plotly](https://plotly.com/python/mapbox-layers/) (some integration with Mapbox requires access token)\n",
    "* [pydeck](https://deckgl.readthedocs.io/en/latest) (based on [deck.gl](https://deck.gl) and with Jupyter widget support)\n",
    "* [Datashader](https://datashader.org/) for rendering spatial visualisations of really large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a4127-8dba-43c7-a899-ec8bc60c5fe5",
   "metadata": {},
   "source": [
    "# Working with .ipynb files \n",
    "\n",
    "Difference between R Markdown and Jupyter notebooks is the serialisation format.\n",
    "* R Mardown saves to markdown (!)\n",
    "* Jupyter notebooks save to `.ipynb` format, which is a JSON format containing cell contents as well as output, and cell metadata\n",
    "\n",
    "JSON format introduces a few challenges:\n",
    "* results in horrible diffs (not good for version control and collaboration)\n",
    "* output in notebooks can make very large files (not good for version control)\n",
    "* output in notebooks can result in sensitive being version-controlled \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac1749a-e129-4cd3-9aaf-c0e897856d16",
   "metadata": {},
   "source": [
    "## Git Hooks to the Rescue! \n",
    "\n",
    "Git hooks allow us to register commands that occur on specific git events, like `pre-commit` and `post-checkout`.\n",
    "\n",
    "[`pre-commit`](https://pre-commit.com/) is a Python library for easily creating custom workflows for your project by registering commands with Git hooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29f086-567e-467d-b5e8-01d22d6a8629",
   "metadata": {},
   "source": [
    "### Workflow 1:\n",
    "\n",
    "Use register a `pre-commit` hook that uses the nbconvert tool to automatically strip out all cell output before it is commited to your git repo:\n",
    "\n",
    "    jupyter nbconvert --clear-output --inplace my_notebook.ipynb\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196cbc3d-74b6-4c6b-a375-a1ee4bc5b1c6",
   "metadata": {},
   "source": [
    "[Jupytext](https://jupytext.readthedocs.io/) is a Python library for two-way synchronisation between .ipynb and Markdown or Python.\n",
    "\n",
    "### Workflow 2:\n",
    "\n",
    "* Register your `.ipynb` files to be paired with either either Markdown or Python (which retains Python/text as specially fenced/commented block).\n",
    "* Do not track `.ipynb` files with version control (and add them to eg `.gitignore`)\n",
    "* Use a [pre-commit hook to automatically convert](https://jupytext.readthedocs.io/en/latest/using-pre-commit.html) your `.ipynb` files to the target format before you commit.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac81dd2c-0220-4766-b093-42c3d982c415",
   "metadata": {},
   "source": [
    "If you're working with notebooks in an operational context where there is any possibility you will be working with personally identifying (or otherwise sensitive)information, you should _absolutely definitely adopt one of these workflows_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2fa3f2-66a0-4739-bd9e-b475a778a49e",
   "metadata": {},
   "source": [
    "# Making Documents with Jupyter Notebook\n",
    "\n",
    "The nbconvert tool that comes with Jupyter allows you to convert to PDF and HTML (as well as other formats).\n",
    "\n",
    "For being repeatable workflows for making high-quality books and reports, I would recommend looking at [Jupyter book](https://jupyterbook.org/), which supports a wide range of export targets and has good integration with Jupytext."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115afd4c-8b72-4456-96fa-12ca20911c62",
   "metadata": {},
   "source": [
    "# Interactivity\n",
    "\n",
    "<center>\n",
    "    <img src=\"/files/img/reactive.svg\" width=900/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9d5ce-4c69-404a-bd6d-f215ec38cf25",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "817c0ed3-cc77-499d-b9f6-babcd4169d69",
   "metadata": {},
   "source": [
    "## ipywidgets Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76ae357-24d0-427a-9394-039ae3564450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "\n",
    "@interact(date=\"2020-01-04\")\n",
    "def interactive_wages(date):\n",
    "    return plot_wage_chloropleth(gdf, jobs_df, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45070e9c-a203-447d-9cca-948776167d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_dropdowns = sorted(set(str(timestamp.date()) for timestamp in jobs_df[\"Date\"]))\n",
    "\n",
    "\n",
    "@interact(date=date_dropdowns)\n",
    "def interactive_wages(date):\n",
    "    return plot_wage_chloropleth(gdf, jobs_df, date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd950878-85bb-4eff-b9f2-85024b4cd4e4",
   "metadata": {},
   "source": [
    "### Some good libraries to choose from\n",
    "* [ipywidgets](https://ipywidgets.readthedocs.io/) (and [Voila](https://github.com/voila-dashboards/voila) for deploying as app)\n",
    "* [Dash](https://plotly.com/dash/)\n",
    "* [Streamlit](https://streamlit.io/)\n",
    "* [Panel](https://panel.holoviz.org/)\n",
    "\n",
    "See my talk on [Python Libraries for Data Apps](https://www.youtube.com/watch?v=jI5zLf9Hvd8&lc) for comparing these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7adef56-c04e-4b39-938e-3fb38227e063",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "<center>\n",
    "    <img src=\"/files/img/python_viz_libs.svg\" width=900/>\n",
    "    <h2><i>Which visualisation library to use?</i></h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9dfa24-02ed-460f-8a46-b062e5a4fc79",
   "metadata": {},
   "source": [
    "### Suggestions\n",
    "\n",
    "* Always try to use one of the high-level library where you can\n",
    "* But still important to be able to work with the low-level interface (with the exception of Vega-Lite)\n",
    "* See my talk on [Python Libraries for Data Apps](https://www.youtube.com/watch?v=jI5zLf9Hvd8&lc), for a guide for choosing between Panel, Dash, Streamlit and Voila\n",
    "* They're all very capable libraries, so pick one and give it a go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268d5e69-83ec-4909-888a-0c930f9c731a",
   "metadata": {},
   "source": [
    "## Python’s strengths\n",
    "\n",
    "* Large user base -> lots of resources and support\n",
    "* Rich ecosystem of libraries (bother data and otherwise)\n",
    "* General-purpose programming language\n",
    "* Well-suited for engineering for scale\n",
    "* Lots of good cloud-based deployment options\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599e7838-0a3d-4625-bded-a9011a3c5262",
   "metadata": {},
   "source": [
    "But at the end of the day, the best tool is the one you can solve your problems with.\n",
    "\n",
    "Pick one, or both, and dive into it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
